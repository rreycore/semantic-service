// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.30.0
// source: chunk.sql

package queries

import (
	"context"

	"github.com/pgvector/pgvector-go"
)

const createChunk = `-- name: CreateChunk :one
INSERT INTO chunks (user_id, document_id, title, text)
VALUES ($1, $2, $3, $4)
RETURNING id, user_id, document_id, title, text
`

type CreateChunkParams struct {
	UserID     int64
	DocumentID int64
	Title      string
	Text       string
}

type CreateChunkRow struct {
	ID         int64
	UserID     int64
	DocumentID int64
	Title      string
	Text       string
}

// Создает один чанк для документа.
// Поле 'embedding' здесь не передается, оно будет NULL при первичной вставке.
func (q *Queries) CreateChunk(ctx context.Context, arg CreateChunkParams) (CreateChunkRow, error) {
	row := q.db.QueryRow(ctx, createChunk,
		arg.UserID,
		arg.DocumentID,
		arg.Title,
		arg.Text,
	)
	var i CreateChunkRow
	err := row.Scan(
		&i.ID,
		&i.UserID,
		&i.DocumentID,
		&i.Title,
		&i.Text,
	)
	return i, err
}

const getChunksByDocumentID = `-- name: GetChunksByDocumentID :many
SELECT id, user_id, document_id, title, text, embedding
FROM chunks
WHERE document_id = $1 AND user_id = $2
ORDER BY id
`

type GetChunksByDocumentIDParams struct {
	DocumentID int64
	UserID     int64
}

// Возвращает все чанки для конкретного документа (для отображения или сборки полного текста).
// ВАЖНО: также проверяет user_id для безопасности.
func (q *Queries) GetChunksByDocumentID(ctx context.Context, arg GetChunksByDocumentIDParams) ([]Chunk, error) {
	rows, err := q.db.Query(ctx, getChunksByDocumentID, arg.DocumentID, arg.UserID)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []Chunk
	for rows.Next() {
		var i Chunk
		if err := rows.Scan(
			&i.ID,
			&i.UserID,
			&i.DocumentID,
			&i.Title,
			&i.Text,
			&i.Embedding,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const searchChunksInDocument = `-- name: SearchChunksInDocument :many

SELECT
    id,
    document_id,
    text,
    embedding <=> $1 AS distance
FROM chunks
WHERE user_id = $2 AND document_id = $3
ORDER BY distance ASC
LIMIT $4
`

type SearchChunksInDocumentParams struct {
	Embedding  pgvector.Vector
	UserID     int64
	DocumentID int64
	Limit      int32
}

type SearchChunksInDocumentRow struct {
	ID         int64
	DocumentID int64
	Text       string
	Distance   interface{}
}

// Ограничиваем количество результатов
// Выполняет семантический поиск по чанкам ОДНОГО документа.
func (q *Queries) SearchChunksInDocument(ctx context.Context, arg SearchChunksInDocumentParams) ([]SearchChunksInDocumentRow, error) {
	rows, err := q.db.Query(ctx, searchChunksInDocument,
		arg.Embedding,
		arg.UserID,
		arg.DocumentID,
		arg.Limit,
	)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []SearchChunksInDocumentRow
	for rows.Next() {
		var i SearchChunksInDocumentRow
		if err := rows.Scan(
			&i.ID,
			&i.DocumentID,
			&i.Text,
			&i.Distance,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}

const searchUserChunks = `-- name: SearchUserChunks :many

SELECT
    id,
    document_id,
    title,
    text,
    embedding <=> $1 AS distance -- Рассчитываем косинусное расстояние до вектора-запроса
FROM chunks
WHERE user_id = $2 -- ВАЖНО: строгая фильтрация по пользователю
ORDER BY distance ASC -- Сортируем по возрастанию расстояния (самые похожие - в начале)
LIMIT $3
`

type SearchUserChunksParams struct {
	Embedding pgvector.Vector
	UserID    int64
	Limit     int32
}

type SearchUserChunksRow struct {
	ID         int64
	DocumentID int64
	Title      string
	Text       string
	Distance   interface{}
}

// Сортировка по ID, чтобы чанки шли в порядке их создания
// Самый важный запрос: выполняет семантический поиск по чанкам.
// Находит N самых похожих чанков для заданного вектора-запроса, но только среди документов конкретного пользователя.
func (q *Queries) SearchUserChunks(ctx context.Context, arg SearchUserChunksParams) ([]SearchUserChunksRow, error) {
	rows, err := q.db.Query(ctx, searchUserChunks, arg.Embedding, arg.UserID, arg.Limit)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var items []SearchUserChunksRow
	for rows.Next() {
		var i SearchUserChunksRow
		if err := rows.Scan(
			&i.ID,
			&i.DocumentID,
			&i.Title,
			&i.Text,
			&i.Distance,
		); err != nil {
			return nil, err
		}
		items = append(items, i)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return items, nil
}
